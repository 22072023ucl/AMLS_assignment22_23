{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c441722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "import pickle\n",
    "import dlib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c03d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image data, use this for task A1, A2, and decision tree for task B1\n",
    "def load_image_to_vector(image_path,image_number):\n",
    "    img_data=[]\n",
    "    for i in range (image_number):\n",
    "        img_color= mpimg.imread(image_path + str(i) + '.jpg')\n",
    "        img=cv2.cvtColor(img_color,cv2.COLOR_BGR2GRAY)\n",
    "        width=np.shape(img_color)[0]\n",
    "        height=np.shape(img_color)[1]\n",
    "        img_vector=img.reshape(width*height)\n",
    "        img_data.append(img_vector)\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51995b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image label, use this for task A1, A2, and decision tree for task B1\n",
    "def get_label(label_path,label_name):\n",
    "    label=pd.read_table(label_path)\n",
    "    y=label[label_name]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563e98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model, will not be used in this test code\n",
    "def LogisticRegression_model(x_train,y_train,x_test,y_test):\n",
    "    clf = LogisticRegression(solver='sag',fit_intercept=True,max_iter=1000)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print('Accuracy on train set:'+str(clf.score(x_train,y_train)))\n",
    "    print('Accuracy on test set: '+str(accuracy_score(y_test,y_pred)))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9825a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model, will not be used in this test code\n",
    "def SVM_model(x_train,y_train,x_test,y_test):\n",
    "    clf=SVC(gamma='auto')\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred =  clf.predict(x_test)\n",
    "    print('Accuracy on train set:'+str(clf.score(x_train,y_train)))\n",
    "    print('Accuracy on test set: '+str(accuracy_score(y_test,y_pred)))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77688f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree model, will not be used in this test code\n",
    "def DecisionTree_model(x_train,y_train,x_test,y_test):\n",
    "    #tree_params={'criterion':'entropy'}\n",
    "    clf = tree.DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=7 )\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred =  clf.predict(x_test)\n",
    "    print('Accuracy on train set:'+str(clf.score(x_train,y_train)))\n",
    "    print('Accuracy on test set: '+str(accuracy_score(y_test,y_pred)))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee820cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model, used for task B1 and B2\n",
    "def train_model(x_train, x_test, y_train, y_test):\n",
    "    model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200,200,4)),  # convolutional layer 1，convolution kernel 3*3\n",
    "    layers.MaxPooling2D((2, 2)),  # pooling layer 1，2*2\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),  # convolutional layer 2，convolution kernel 3*3\n",
    "    layers.MaxPooling2D((2, 2)),  # pooling layer 2，2*2\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),  # convolutional layer 3，convolution kernel 3*3\n",
    "    layers.Dropout(.2),\n",
    "\n",
    "\n",
    "    layers.Flatten(),  # Flatten\n",
    "    layers.Dense(128, activation='relu'),  # FP layer\n",
    "    layers.Dropout(.2),\n",
    "    layers.Dense(64, activation='relu'),  # FP layer\n",
    "    layers.Dense(10)  # output layer\n",
    "    ])\n",
    "    model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0a031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for high dimention image data, use this for task A1, A2\n",
    "def img_data_pca(img_data,dimention):\n",
    "    pca = PCA(n_components = 100)\n",
    "    pca.fit(img_data)\n",
    "    pca_data=pca.transform(img_data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de275ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get face feature, use this for task A1\n",
    "def face_feature(img_path,img_number):\n",
    "    predictor_path = \"./A1/shape_predictor_68_face_landmarks.dat\"\n",
    "    face_rec_model_path = \"./A1/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "    detector = dlib.get_frontal_face_detector() #a detector to find the faces\n",
    "    sp = dlib.shape_predictor(predictor_path ) #shape predictor to find face landmarks\n",
    "    facerec = dlib.face_recognition_model_v1(face_rec_model_path) #face recognition model\n",
    "    img_data=np.zeros((img_number,128))\n",
    "    for i in range (img_number):\n",
    "        img = dlib.load_rgb_image('./datasets/'+img_path+'/img/' + str(i) + '.jpg')\n",
    "        dets = detector(img, 1)  #Extract the face area in the picture\n",
    "        for k, d in enumerate(dets):\n",
    "            shape = sp(img, d)\n",
    "            face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "            img_data[i,:]=face_descriptor\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c8f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get lip feature, use this for task A2\n",
    "def lip_feature(img_path,img_number):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('./A2/shape_predictor_68_face_landmarks.dat')\n",
    "    lip_data=[]\n",
    "    nothing_number=[]\n",
    "    for i in range (img_number):\n",
    "        img = cv2.imread('./datasets/'+img_path+'/img/'+str(i)+'.jpg')\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        positions_68_arr = []\n",
    "        faces = detector(img_gray, 0)\n",
    "        if len(faces) !=0:\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(img, faces[0]).parts()])\n",
    "            for idx, point in enumerate(landmarks):\n",
    "                #coordinates of 68 points\n",
    "                pos = (point[0, 0], point[0, 1])\n",
    "                positions_68_arr.append(pos)\n",
    "            positions_lip_arr = []\n",
    "            for i in range(48, 68):\n",
    "                positions_lip_arr.append(positions_68_arr[i][0])\n",
    "                positions_lip_arr.append(positions_68_arr[i][1])\n",
    "            lip_data.append(positions_lip_arr)\n",
    "        else:\n",
    "            nothing_number.append(i)\n",
    "            continue\n",
    "    return lip_data,nothing_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa0973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_image(img_path,img_number):\n",
    "    img_data=[]\n",
    "    for i in range (img_number):\n",
    "        img = mpimg.imread('./datasets/'+img_path+'/img/' + str(i) + '.png')\n",
    "        img=cv2.resize(img,(200,200))\n",
    "        img_data.append(img)\n",
    "    img_data=np.array(img_data)\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c616a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cartoon_label(label_path,label_name,label_number):\n",
    "    label=pd.read_table('./datasets/'+label_path+'/labels.csv')\n",
    "    label= label[label_name]\n",
    "    label=label[:label_number]\n",
    "    label= np.array(label)\n",
    "    vector2arr = np.mat(label)\n",
    "    label = vector2arr.A.T\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22295d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c6de01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.89      0.88       500\n",
      "           1       0.89      0.87      0.88       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "CPU times: total: 797 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "# A1 Logistic Regression raw data\n",
    "##Data without dimensionality reduction and feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test= transfer.fit_transform(img_data_test)\n",
    "#get label_test\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','gender')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A1/LogisticRegression_gender.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8c2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.48      0.49       500\n",
      "           1       0.50      0.52      0.51       500\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.50      0.50      0.50      1000\n",
      "weighted avg       0.50      0.50      0.50      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A1 Logistic Regression PCA data\n",
    "#Data with dimensionality reduction by PCA\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','gender')\n",
    "#pca for image data\n",
    "img_data_test=img_data_pca(img_data_test,100)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A1/LogisticRegression_gender_PCA.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3b663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.96      0.97       500\n",
      "           1       0.96      0.97      0.97       500\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A1 Logistic Regression feature data\n",
    "#Data with feature extraction\n",
    "#get and preprocess image data for testing\n",
    "#img_data_test=face_feature_read('face_feature_test')\n",
    "img_data_test=face_feature('celeba_test',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','gender')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A1/LogisticRegression_gender_dlib.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "403c3790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.88      0.89       500\n",
      "           1       0.88      0.89      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A1 SVM raw data\n",
    "##Data without dimensionality reduction and feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "img_data_test = transfer.fit_transform(img_data_test)\n",
    "#get label_test\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','gender')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A1/SVM_gender.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3616bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5\n"
     ]
    }
   ],
   "source": [
    "#A1 SVM PCA data\n",
    "#Data with dimensionality reduction by PCA\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','gender')\n",
    "#pca for image data\n",
    "img_data_test=img_data_pca(img_data_test,100)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A1/SVM_gender_PCA.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "#print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087a096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.96      0.97       500\n",
      "           1       0.96      0.97      0.97       500\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A1 SVM feature data\n",
    "#Data with feature extraction\n",
    "#get and preprocess image data for testing\n",
    "#img_data_test=face_feature_read('face_feature_test')\n",
    "img_data_test=face_feature('celeba_test',1000)\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','gender')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A1/SVM_gender_dlib.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86493cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.86      0.86       500\n",
      "           1       0.86      0.86      0.86       500\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A2 Logistic Regression raw data\n",
    "##Data without dimensionality reduction and feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test= transfer.fit_transform(img_data_test)\n",
    "#get label_test\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','smiling')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A2/LogisticRegression_smiling.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d68ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.56      0.56       500\n",
      "           1       0.55      0.54      0.55       500\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.55      0.55      0.55      1000\n",
      "weighted avg       0.55      0.55      0.55      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A2 Logistic Regression PCA data\n",
    "#Data with dimensionality reduction by PCA\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','smiling')\n",
    "#pca for image data\n",
    "img_data_test=img_data_pca(img_data_test,100)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A2/LogisticRegression_smiling_PCA.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f62682a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9036885245901639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.92      0.90       477\n",
      "           1       0.92      0.88      0.90       499\n",
      "\n",
      "    accuracy                           0.90       976\n",
      "   macro avg       0.90      0.90      0.90       976\n",
      "weighted avg       0.90      0.90      0.90       976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A2 Logistic Regression feature data\n",
    "#Data with feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test,nothing_number_test=lip_feature('celeba_test',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','smiling')\n",
    "for i in range(len(nothing_number_test)):\n",
    "    del label_test[nothing_number_test[i]]\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A2/LogisticRegression_smiling_dlib_lip.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a01e1bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.90      0.88       500\n",
      "           1       0.90      0.86      0.88       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A2 SVM raw data\n",
    "##Data without dimensionality reduction and feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test)\n",
    "#get label_test\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','smiling')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A2/SVM_smiling.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6af84b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5\n"
     ]
    }
   ],
   "source": [
    "#A2 SVM PCA data\n",
    "#Data with dimensionality reduction by PCA\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('./datasets/celeba_test/img/',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','smiling')\n",
    "#pca for image data\n",
    "img_data_test=img_data_pca(img_data_test,100)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A2/SVM_smiling_PCA.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "#print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a680aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8944672131147541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.92      0.90       477\n",
      "           1       0.92      0.87      0.89       499\n",
      "\n",
      "    accuracy                           0.89       976\n",
      "   macro avg       0.90      0.90      0.89       976\n",
      "weighted avg       0.90      0.89      0.89       976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A2 SVM feature data\n",
    "#Data with feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test,nothing_number_test=lip_feature('celeba_test',1000)\n",
    "transfer=StandardScaler()\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('./datasets/celeba_test/labels.csv','smiling')\n",
    "for i in range(len(nothing_number_test)):\n",
    "    del label_test[nothing_number_test[i]]\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./A2/SVM_smiling_dlib_lip.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82db9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image data ,this is used for Decision Tree for B1\n",
    "def load_image_to_vector_DT(image_path,image_number):\n",
    "    img_data=[]\n",
    "    for i in range (image_number):\n",
    "        img_color= mpimg.imread(image_path + str(i) + '.png')\n",
    "        img=cv2.cvtColor(img_color,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img,(200,200))\n",
    "        img_vector=img.reshape(40000)\n",
    "        img_data.append(img_vector)\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8380fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "           2       1.00      1.00      1.00       500\n",
      "           3       1.00      1.00      1.00       500\n",
      "           4       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#B1 decision tree \n",
    "#get image data\n",
    "img_data_test=load_image_to_vector_DT('./datasets/cartoon_set_test/img/',2500)\n",
    "transfer=StandardScaler()\n",
    "img_data_test= StandardScaler().fit_transform(img_data_test)\n",
    "#get label\n",
    "label_test=get_label('./datasets/cartoon_set_test/labels.csv','face_shape')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./B1/DecisionTree_shape.dat\",\"rb\"))\n",
    "\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6087bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-12 15:11:22         4591\n",
      "metadata.json                                  2023-01-12 15:11:22           64\n",
      "variables.h5                                   2023-01-12 15:11:22    208843856\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "79/79 [==============================] - 6s 76ms/step - loss: 0.0031 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "#B1 CNN\n",
    "#get image data\n",
    "img_data_test=get_color_image('cartoon_set_test',2500)\n",
    "#get label\n",
    "label_test=get_cartoon_label('cartoon_set_test','face_shape',2500)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./B1/CNN_shape.dat\",\"rb\"))\n",
    "label_pred=loaded_model.evaluate(img_data_test,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ef5212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-12 17:36:04         4607\n",
      "metadata.json                                  2023-01-12 17:36:04           64\n",
      "variables.h5                                   2023-01-12 17:36:06    418859832\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "79/79 [==============================] - 13s 167ms/step - loss: 0.3878 - accuracy: 0.8304\n"
     ]
    }
   ],
   "source": [
    "#B2 CNN\n",
    "#get image data\n",
    "img_data_test=get_color_image('cartoon_set_test',2500)\n",
    "#get label\n",
    "label_test=get_cartoon_label('cartoon_set_test','eye_color',2500)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"./B2/CNN_color.dat\",\"rb\"))\n",
    "label_pred=loaded_model.evaluate(img_data_test,label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062e07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
