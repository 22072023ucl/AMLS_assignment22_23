{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c441722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "import pickle\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c03d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_to_vector(image_path,image_number):\n",
    "    img_data=[]\n",
    "    for i in range (image_number):\n",
    "        img_color= mpimg.imread(image_path + str(i) + '.jpg')\n",
    "        img=cv2.cvtColor(img_color,cv2.COLOR_BGR2GRAY)\n",
    "        width=np.shape(img_color)[0]\n",
    "        height=np.shape(img_color)[1]\n",
    "        img_vector=img.reshape(width*height)\n",
    "        img_data.append(img_vector)\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51995b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label_path,label_name):\n",
    "    label=pd.read_table(label_path)\n",
    "    y=label[label_name]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563e98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_model(x_train,y_train,x_test,y_test):\n",
    "    clf = LogisticRegression(solver='sag',fit_intercept=True,max_iter=1000)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print('Accuracy on train set:'+str(clf.score(x_train,y_train)))\n",
    "    print('Accuracy on test set: '+str(accuracy_score(y_test,y_pred)))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0a031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_data_pca(img_data,dimention):\n",
    "    pca = PCA(n_components = 100)\n",
    "    pca.fit(img_data)\n",
    "    pca_data=pca.transform(img_data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de275ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_feature(img_path,img_number):\n",
    "    predictor_path = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "    face_rec_model_path = \"./dlib_face_recognition_resnet_model_v1.dat\"\n",
    "    detector = dlib.get_frontal_face_detector() #a detector to find the faces\n",
    "    sp = dlib.shape_predictor(predictor_path ) #shape predictor to find face landmarks\n",
    "    facerec = dlib.face_recognition_model_v1(face_rec_model_path) #face recognition model\n",
    "    img_data=np.zeros((img_number,128))\n",
    "    for i in range (img_number):\n",
    "        img = dlib.load_rgb_image('../datasets/'+img_path+'/img/' + str(i) + '.jpg')\n",
    "        dets = detector(img, 1)  #Extract the face area in the picture\n",
    "        for k, d in enumerate(dets):\n",
    "            shape = sp(img, d)\n",
    "            face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "            img_data[i,:]=face_descriptor\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8d4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_feature_read(csv_name):\n",
    "    img_data = pd.read_csv('./'+csv_name+'.csv')\n",
    "    img_data=np.array(img_data)\n",
    "    img_data=img_data[:,1:]\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc958808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_curve(x_train,y_train,x_test,y_test):\n",
    "    l2_iter = []\n",
    "    l2_iter_t = []\n",
    "    iters = np.arange(300,500,50)\n",
    "    for i in iters:\n",
    "        lr2 = LogisticRegression(penalty=\"l2\",solver='sag',max_iter=i,random_state=0)\n",
    "        lr2 = lr2.fit(x_train,y_train)\n",
    "        l2_iter.append(accuracy_score(lr2.predict(x_train),y_train))\n",
    "        l2_iter_t.append(accuracy_score(lr2.predict(x_test),y_test))\n",
    "    plt.plot(figsize=(20,6))\n",
    "    plt.plot(iters,l2_iter,label='accuracy')\n",
    "    plt.plot(iters,l2_iter_t,label='val_accuracy')\n",
    "    plt.xticks(iters)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ebae990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set:1.0\n",
      "Accuracy on test set: 0.868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.87      0.86       241\n",
      "           1       0.88      0.86      0.87       259\n",
      "\n",
      "    accuracy                           0.87       500\n",
      "   macro avg       0.87      0.87      0.87       500\n",
      "weighted avg       0.87      0.87      0.87       500\n",
      "\n",
      "CPU times: total: 12min 22s\n",
      "Wall time: 12min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccgba_c8rtor4\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Data without dimensionality reduction and feature extraction\n",
    "#get image data\n",
    "img_data=load_image_to_vector('../datasets/celeba/img/',5000)\n",
    "#get label\n",
    "label=get_label('../datasets/celeba/labels.csv','gender')\n",
    "#Standardize the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, label,test_size=0.1,random_state=0)\n",
    "transfer=StandardScaler()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)\n",
    "#train the model and report accuracy\n",
    "model=LogisticRegression_model(x_train,y_train,x_test,y_test)\n",
    "#save model\n",
    "pickle.dump(model,open(\"LogisticRegression_gender.dat\",\"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c260345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set:0.804\n",
      "Accuracy on test set: 0.412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      0.39      0.39       241\n",
      "           1       0.43      0.43      0.43       259\n",
      "\n",
      "    accuracy                           0.41       500\n",
      "   macro avg       0.41      0.41      0.41       500\n",
      "weighted avg       0.41      0.41      0.41       500\n",
      "\n",
      "CPU times: total: 37.2 s\n",
      "Wall time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Data with dimensionality reduction by PCA\n",
    "#get image data\n",
    "img_data=load_image_to_vector('../datasets/celeba/img/',5000)\n",
    "#get label\n",
    "label=get_label('../datasets/celeba/labels.csv','gender')\n",
    "#pca for image data\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, label,test_size=0.1,random_state=0)\n",
    "x_train=img_data_pca(x_train,100)\n",
    "x_test=img_data_pca(x_test,100)\n",
    "#Standardize the data\n",
    "transfer=StandardScaler()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)\n",
    "#train the model and report accuracy\n",
    "model=LogisticRegression_model(x_train,y_train,x_test,y_test)\n",
    "#save model\n",
    "pickle.dump(model,open(\"LogisticRegression_gender_PCA.dat\",\"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a769d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set:0.9764444444444444\n",
      "Accuracy on test set: 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.95      0.96       241\n",
      "           1       0.95      0.98      0.97       259\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.97      0.97      0.97       500\n",
      "weighted avg       0.97      0.97      0.97       500\n",
      "\n",
      "CPU times: total: 17min 49s\n",
      "Wall time: 18min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Data with feature extraction\n",
    "#img_data=face_feature_read('face_feature_train')\n",
    "img_data=face_feature('celeba',5000)\n",
    "#img_data=face_feature('celeba',5000)\n",
    "#get label\n",
    "label=get_label('../datasets/celeba/labels.csv','gender')\n",
    "#Standardize the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, label,test_size=0.1,random_state=0)\n",
    "transfer=StandardScaler()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)\n",
    "#train the model and report accuracy\n",
    "model=LogisticRegression_model(x_train,y_train,x_test,y_test)\n",
    "#save model\n",
    "pickle.dump(model,open(\"LogisticRegression_gender_dlib.dat\",\"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dba0f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeZUlEQVR4nO3de5QV5Z3u8e8TLkG8toCEm8LkqNwbtEWD47VHj55BiIxEHMcoEZUkkIgrUSTxkolZwyGajFGPiB68JChBTGccV6IRb6x4VGi0EbkpgoYWhRZBQoxcf+ePXd1uNn3ZBb3p1n4+a+3Frqr3feutrrX3w1u1q0oRgZmZWb6+1NQdMDOzzxcHh5mZpeLgMDOzVBwcZmaWioPDzMxSad3UHdgfOnbsGD179mzqbpiZfa4sXLjww4jolDu/RQRHz549KS8vb+pumJl9rkh6t7b5PlRlZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKi3iOo699ZP/XsLStZubuhtmZnutb9dDuOm8fo3apkccZmaWikcc9WjslDYz+yLwiMPMzFJxcJiZWSoODjMzS6WgwSHpHEkrJK2UNKmW5UWSyiS9Lmm+pP7J/GMlVWS9Nku6OqvehKTdJZKmFnIbzMxsdwU7OS6pFXAXcBZQCSyQ9HhELM0qNhmoiIjzJfVOypdGxApgUFY77wFlyfQZwAhgYERslXREobbBzMz2VMgRxxBgZUSsiohtwCwyX/jZ+gLPAETEcqCnpM45ZUqBtyOi+r7w3wamRMTWpN76Qm2AmZntqZDB0Q1YkzVdmczLtggYCSBpCHAU0D2nzGjgkazpY4BTJL0i6QVJJzRqr83MrF6FDA7VMi9ypqcARZIqgAnAa8COmgaktsBw4NGsOq2BIuAk4IfAbEl7rEvSlZLKJZVXVVXty3aYmVmWQl4AWAn0yJruDqzNLhARm4ExAMmX/+rkVe1c4NWIWJfT7u8iIoD5knYBHYHd0iEipgPTAUpKSnIDy8zM9lIhRxwLgKMl9UpGDqOBx7MLSDosWQYwFpiXhEm1i9j9MBXA74Ezk/rHAG2BDxu/+2ZmVpuCjTgiYoek8cBTQCtgRkQskTQuWT4N6AM8JGknsBS4vLq+pPZkfpF1VU7TM4AZkt4AtgGXJqMPMzPbD9QSvnNLSkqivLy8qbthZva5ImlhRJTkzveV42ZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapODjMzCwVB4eZmaXi4DAzs1QcHGZmloqDw8zMUnFwmJlZKg4OMzNLxcFhZmapFDQ4JJ0jaYWklZIm1bK8SFKZpNclzZfUP5l/rKSKrNdmSVfn1P2BpJDUsZDbYGZmu2tdqIYltQLuAs4CKoEFkh6PiKVZxSYDFRFxvqTeSfnSiFgBDMpq5z2gLKvtHkm7fylU/83MrHaFHHEMAVZGxKqI2AbMAkbklOkLPAMQEcuBnpI655QpBd6OiHez5v0SuBaIgvTczMzqVMjg6AasyZquTOZlWwSMBJA0BDgK6J5TZjTwSPWEpOHAexGxqLE7bGZmDStkcKiWebkjhClAkaQKYALwGrCjpgGpLTAceDSZbg/8CLixwZVLV0oql1ReVVW1VxtgZmZ7Ktg5DjIjjB5Z092BtdkFImIzMAZAkoDVyavaucCrEbEumf4q0AtYlClOd+BVSUMi4oOctqcD0wFKSkp8SMvMrJEUMjgWAEdL6kXm5PZo4F+zC0g6DPgkOQcyFpiXhEm1i8g6TBURi4Ejsuq/A5RExIcF2gYzM8tRsOCIiB2SxgNPAa2AGRGxRNK4ZPk0oA/wkKSdwFLg8ur6yWGps4CrCtVHMzNLr5AjDiLiD8AfcuZNy3r/EnB0HXU/ATo00H7Pfe+lmZml4SvHzcwsFQeHmZml4uAwM7NUHBxmZpaKg8PMzFJxcJiZWSoODjMzS8XBYWZmqTg4zMwsFQeHmZml4uAwM7NUHBxmZpaKg8PMzFJxcJiZWSoODjMzS8XBYWZmqTg4zMwsFQeHmZml4uAwM7NUHBxmZpaKg8PMzFJxcJiZWSoODjMzS8XBYWZmqTg4zMwsFQeHmZml4uAwM7NUGgwOScMkOWDMzAzIb8QxGnhL0lRJfQrdITMza94aDI6I+DdgMPA2cL+klyRdKenghupKOkfSCkkrJU2qZXmRpDJJr0uaL6l/Mv9YSRVZr82Srk6W/VzS8qROmaTDUm6zmZntg9b5FIqIzZIeAw4ArgbOB34o6VcRcUdtdSS1Au4CzgIqgQWSHo+IpVnFJgMVEXG+pN5J+dKIWAEMymrnPaAsqfM0cH1E7JD0v4HrgetSbLOZNbHt27dTWVnJp59+2tRdMaBdu3Z0796dNm3a5FW+weCQdB7wLeCrwK+BIRGxXlJ7YBlQa3AAQ4CVEbEqaWcWMALIDo6+wH8ARMRyST0ldY6IdVllSoG3I+LdpNyfspa9DFzQ8GaaWXNSWVnJwQcfTM+ePZHU1N1p0SKCDRs2UFlZSa9evfKqk885jlHALyNiYET8PCLWJyv7hEyg1KUbsCZrujKZl20RMBJA0hDgKKB7TpnRwCN1rONbwB9rW5AcTiuXVF5VVVVPN81sf/v000/p0KGDQ6MZkESHDh1Sjf7yCY6bgPlZKzlAUk+AiHimvv7UMi9ypqcARZIqgAnAa8COrHW1BYYDj+7RuPSjpOzM2lYeEdMjoiQiSjp16lRPN82sKTg0mo+0+yKfcxyPAkOzpncm805ooF4l0CNrujuwNrtARGwGxgAo0/PVyavaucCrOYeukHQpMIzM+ZDcMDIzswLKZ8TROiK2VU8k79vmUW8BcLSkXsnIYTTweHYBSYclywDGAvOSMKl2ETmHqSSdQ+Zk+PDkcJmZme1H+QRHlaTh1ROSRgAfNlQpInYA44GnyJxEnx0RSySNkzQuKdYHWCJpOZnRxfez1tOezC+yfpfT9J3AwcDTyU91p+WxDWZm+92OHTsaLvQ5lE9wjAMmS/qLpDVk/rd/VT6NR8QfIuKYiPhqRPwsmTctIqYl71+KiKMjondEjIyIjVl1P4mIDhHxcU6b/yMiekTEoOQ1DjOzlL7+9a9z/PHH069fP6ZPnw7Ak08+yXHHHUdxcTGlpaUAbNmyhTFjxjBgwAAGDhzIY489BsBBBx1U09acOXO47LLLALjsssu45pprOOOMM7juuuuYP38+Q4cOZfDgwQwdOpQVK1YAsHPnTn7wgx/UtHvHHXfwzDPPcP7559e0+/TTTzNy5Mj98edIpcFzHBHxNnCSpIMARcRfC98tM2spfvLfS1i6dnPDBVPo2/UQbjqvX71lZsyYweGHH87f//53TjjhBEaMGMEVV1zBvHnz6NWrFx999BEAP/3pTzn00ENZvHgxABs3bqyvWQDefPNN5s6dS6tWrdi8eTPz5s2jdevWzJ07l8mTJ/PYY48xffp0Vq9ezWuvvUbr1q356KOPKCoq4rvf/S5VVVV06tSJ+++/nzFjxuz7H6SR5XUBoKR/BvoB7arPvkfEvxewX2ZmBfWrX/2KsrLMdcVr1qxh+vTpnHrqqTXXMhx++OEAzJ07l1mzZtXUKyoqarDtUaNG0apVKwA+/vhjLr30Ut566y0ksX379pp2x40bR+vWrXdb3yWXXMJvfvMbxowZw0svvcRDDz3USFvcePK5AHAa0B44A7iPzAV38+utZGaWp4ZGBoXw/PPPM3fuXF566SXat2/P6aefTnFxcc1hpGwRUevPVbPn5V4DceCBB9a8v+GGGzjjjDMoKyvjnXfe4fTTT6+33TFjxnDeeefRrl07Ro0aVRMszUk+5ziGRsQ3gY0R8RPga+z+M1szs8+Vjz/+mKKiItq3b8/y5ct5+eWX2bp1Ky+88AKrV2euCKg+VHX22Wdz55131tStPlTVuXNnli1bxq5du2pGLnWtq1u3zLXPDzzwQM38s88+m2nTptWcQK9eX9euXenatSu33HJLzXmT5iaf4KiO0k8kdQW2A/ldl25m1gydc8457Nixg4EDB3LDDTdw0kkn0alTJ6ZPn87IkSMpLi7mwgsvBODHP/4xGzdupH///hQXF/Pcc88BMGXKFIYNG8aZZ55Jly5d6lzXtddey/XXX8/JJ5/Mzp07a+aPHTuWI488koEDB1JcXMzDDz9cs+ziiy+mR48e9O3bt0B/gX2jhq6fk3QDmftRlZK5CWEA90bEjYXvXuMoKSmJ8vLypu6GmSWWLVtGnz5+SkNdxo8fz+DBg7n88sv32zpr2yeSFkZESW7Zeg+eJQ9weiYiNgGPSXoCaJf7E1kzM2scxx9/PAceeCC33XZbU3elTvUGR0TsknQbmfMaRMRWYOv+6JiZWUu0cOHCpu5Cg/I5x/EnSf8i35HMzMzI7zqOa4ADgR2SPiVz19uIiEMK2jMzM2uW8rlyvMFHxJqZWcuRzwWAp9Y2PyLmNX53zMysucvnUNUPs963I/NI2IXAmQXpkZmZNWv5HKo6L3taUg9gasF6ZGbWzBx00EFs2bKlqbvRbOTzq6pclUD/xu6ImZnVr7k83yOfcxx38Nmzwr8EDAIWFbBPZtaS/HESfLC4cdv8ygA4d0qdi6+77jqOOuoovvOd7wBw8803I4l58+axceNGtm/fzi233MKIESMaXNWWLVsYMWJErfUeeughbr31ViQxcOBAfv3rX7Nu3TrGjRvHqlWrALj77rvp2rUrw4YN44033gDg1ltvZcuWLdx8882cfvrpDB06lBdffJHhw4dzzDHHcMstt7Bt2zY6dOjAzJkz6dy5M1u2bGHChAmUl5cjiZtuuolNmzbxxhtv8Mtf/hKAe++9l2XLlvGLX/xin/68+ZzjyL5Xxw7gkYh4cZ/WambWhEaPHs3VV19dExyzZ8/mySefZOLEiRxyyCF8+OGHnHTSSQwfPrzWO9hma9euHWVlZXvUW7p0KT/72c948cUX6dixY81NDL/3ve9x2mmnUVZWxs6dO9myZUuDz/jYtGkTL7zwApC5yeLLL7+MJO677z6mTp3KbbfdVutzQ9q2bcvAgQOZOnUqbdq04f777+eee+7Z1z9fXsExB/g0InYCSGolqb2f921mjaKekUGhDB48mPXr17N27VqqqqooKiqiS5cuTJw4kXnz5vGlL32J9957j3Xr1vGVr3yl3rYigsmTJ+9R79lnn+WCCy6gY8eOwGfP23j22WdrnrHRqlUrDj300AaDo/qGiwCVlZVceOGFvP/++2zbtq3m+SF1PTfkzDPP5IknnqBPnz5s376dAQMGpPxr7SmfcxzPAAdkTR8AzN3nNZuZNaELLriAOXPm8Nvf/pbRo0czc+ZMqqqqWLhwIRUVFXTu3HmP52zUpq56dT1vozatW7dm165dNdP1Pd9jwoQJjB8/nsWLF3PPPffUlK1rfWPHjuWBBx5o1KcJ5hMc7SKi5ucEyfv2jbJ2M7MmMnr0aGbNmsWcOXO44IIL+PjjjzniiCNo06YNzz33HO+++25e7dRVr7S0lNmzZ7Nhwwbgs+dtlJaWcvfddwOZ545v3ryZzp07s379ejZs2MDWrVt54okn6l1f9fM9HnzwwZr5dT035MQTT2TNmjU8/PDDXHTRRfn+eeqVT3D8TdJx1ROSjgf+3ihrNzNrIv369eOvf/0r3bp1o0uXLlx88cWUl5dTUlLCzJkz6d27d17t1FWvX79+/OhHP+K0006juLiYa665BoDbb7+d5557jgEDBnD88cezZMkS2rRpw4033siJJ57IsGHD6l33zTffzKhRozjllFNqDoNB3c8NAfjGN77BySefnNdjb/ORz/M4TgBmAWuTWV2ACyOi+d/CMeHncZg1L34ex/41bNgwJk6cSGlpaZ1lGu15HAARsUBSb+BYMjc4XB4R21P33MzM9qtNmzYxZMgQiouL6w2NtPK5juO7wMyIeCOZLpJ0UUT8n0brhZlZM7d48WIuueSS3eZ9+ctf5pVXXmmiHjXssMMO480332z0dvP5Oe4VEXFX9UREbJR0BeDgMLO9luZXR83BgAEDqKioaOpuFERDpyxy5XNy/EvZD3GS1Apom7JfZmY12rVrx4YNG1J/YVnjiwg2bNhAu3bt8q6Tz4jjKWC2pGlkbj0yDvjj3nXRzAy6d+9OZWUlVVVVTd0VIxPk3bt3z7t8PsFxHXAl8G0yJ8dfI/PLKjOzvdKmTZuaK57t86fBQ1URsQt4GVgFlAClwLIC98vMzJqpOoND0jGSbpS0DLgTWAMQEWdExJ111ctp4xxJKyStlDSpluVFksokvS5pvqT+yfxjJVVkvTZLujpZdrikpyW9lfzbOFe0mJlZXuobcSwnM7o4LyL+MSLuAHbm23ByEv0u4FygL3CRpL45xSYDFRExEPgmcDtARKyIiEERMQg4HvgEKEvqTAKeiYijydxHa49AMjOzwqkvOP4F+AB4TtK9kkrJnOPI1xBgZUSsiohtZK4+z725fV8yX/5ExHKgp6TOOWVKgbcjovrGMSOA6hu0PAh8PUWfzMxsH9UZHBFRFhEXAr2B54GJQGdJd0s6O4+2u5Ec3kpUJvOyLQJGAkgaAhwF5J7aHw08kjXdOSLeT/r4PnBEbSuXdKWkcknl/uWGmVnjyefk+N8iYmZEDCPzpV5BfoeHahud5P5oewpQJKkCmEDmF1s1z0aU1BYYDjyax/py+z09IkoioqRTp05pq5uZWR3y+TlujYj4CLgneTWkEuiRNd2dz26UWN3eZmAMQHKR4erkVe1c4NWIWJc1b52kLhHxvqQuwPo022BmZvsmnyvH99YC4GhJvZKRw2jg8ewCkg5LlgGMBeYlYVLtInY/TEXSxqXJ+0uB/2r0npuZWZ1SjTjSiIgdksaTufK8FTAjIpZIGpcsnwb0AR6StBNYClxeXV9Se+As4KqcpqeQuZL9cuAvwKhCbYOZme2pwedxfBH4eRxmZunV9TyOQh6qMjOzLyAHh5mZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWioPDzMxSKWhwSDpH0gpJKyVNqmV5kaQySa9Lmi+pf9aywyTNkbRc0jJJX0vmD5L0sqQKSeWShhRyG8zMbHcFCw5JrYC7gHOBvsBFkvrmFJsMVETEQOCbwO1Zy24HnoyI3kAxsCyZPxX4SUQMAm5Mps3MbD8p5IhjCLAyIlZFxDZgFjAip0xf4BmAiFgO9JTUWdIhwKnA/02WbYuITUmdAA5J3h8KrC3gNpiZWY7WBWy7G7Ama7oSODGnzCJgJPDn5JDTUUB3YCdQBdwvqRhYCHw/Iv4GXA08JelWMsE3tLaVS7oSuBLgyCOPbKRNMjOzQo44VMu8yJmeAhRJqgAmAK8BO8gE2nHA3RExGPgbUH2O5NvAxIjoAUwkGZXssaKI6RFREhElnTp12tdtMTOzRCFHHJVAj6zp7uQcVoqIzcAYAEkCViev9kBlRLySFJ3DZ8FxKfD95P2jwH2F6LyZmdWukCOOBcDRknpJaguMBh7PLpD8cqptMjkWmBcRmyPiA2CNpGOTZaXA0uT9WuC05P2ZwFsF3AYzM8tRsBFHROyQNB54CmgFzIiIJZLGJcunAX2AhyTtJBMMl2c1MQGYmQTLKpKRCXAFcLuk1sCnJOcxzMxs/1BE7mmHL56SkpIoLy9v6m6YmX2uSFoYESW5833luJmZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWioPDzMxScXCYmVkqBQ0OSedIWiFppaRJtSwvklQm6XVJ8yX1z1p2mKQ5kpZLWibpa1nLJiTtLpE0tZDbYGZmu2tdqIYltQLuAs4CKoEFkh6PiKVZxSYDFRFxvqTeSfnSZNntwJMRcYGktkD7pN0zgBHAwIjYKumIQm2DmZntqWDBAQwBVkbEKgBJs8h84WcHR1/gPwAiYrmknpI6A38HTgUuS5ZtA7Yldb4NTImIrcmy9QXbgj9Ogg8WF6x5M7OC+8oAOHdKozZZyENV3YA1WdOVybxsi4CRAJKGAEcB3YF/AKqA+yW9Juk+SQcmdY4BTpH0iqQXJJ1Q28olXSmpXFJ5VVVV422VmVkLV8gRh2qZFznTU4DbJVUAi4HXgB1AG+A4YEJEvCLpdmAScAOZPhcBJwEnALMl/UNE7NZ2REwHpgOUlJTkrjc/jZzSZmZfBIUMjkqgR9Z0d2BtdoGI2AyMAZAkYHXyag9URsQrSdE5ZIKjut3fJUExX9IuoCOZEYqZmRVYIQ9VLQCOltQrObk9Gng8u0Dyy6m2yeRYYF5EbI6ID4A1ko5NlpXy2bmR3wNnJvWPAdoCHxZwO8zMLEvBRhwRsUPSeOApoBUwIyKWSBqXLJ8G9AEekrSTTDBcntXEBGBmEiyrSEYmwAxghqQ3yJwwvzT3MJWZmRWOWsJ3bklJSZSXlzd1N8zMPlckLYyIktz5vnLczMxScXCYmVkqDg4zM0vFwWFmZqm0iJPjkqqAd/eyekf8c9/myPul+fE+aZ72Zb8cFRGdcme2iODYF5LKa/tVgTUt75fmx/ukeSrEfvGhKjMzS8XBYWZmqTg4Gja9qTtgtfJ+aX68T5qnRt8vPsdhZmapeMRhZmapODjMzCyVFh0cktpJmi9pkaQlkn6SzD9c0tOS3kr+Lcqqc72klZJWSPqfTdf7L6569svNkt6TVJG8/ldWHe+X/UBSq+SpnE8k0/6sNLFa9knBPyct+hxH8vCoAyNii6Q2wJ+B75N5nO1HETFF0iSgKCKuk9QXeITM89S7AnOBYyJiZxNtwhdSPfvlHGBLRNyaU977ZT+RdA1QAhwSEcMkTcWflSZVyz65mQJ/Tlr0iCMytiSTbZJXACOAB5P5DwJfT96PAGZFxNaIWA2sJLMTrBHVs1/q4v2yH0jqDvwzcF/WbH9WmlAd+6QujbZPWnRwQM0wrwJYDzydPK62c0S8D5D8e0RSvBuwJqt6ZTLPGlkd+wVgvKTXJc3IOizi/bJ//CdwLbAra54/K03rP9lzn0CBPyctPjgiYmdEDCLzTPQhkvrXU1y1NVGQjrVwdeyXu4GvAoOA94HbkuLeLwUmaRiwPiIW5lullnneJ42onn1S8M9Jiw+OahGxCXiezHH0dZK6ACT/rk+KVQI9sqp1B9buv162PNn7JSLWJYGyC7iXz4bZ3i+FdzIwXNI7wCzgTEm/wZ+VplTrPtkfn5MWHRySOkk6LHl/APBPwHLgceDSpNilwH8l7x8HRkv6sqRewNHA/P3a6Ragrv1S/QWVOB94I3nv/VJgEXF9RHSPiJ7AaODZiPg3/FlpMnXtk/3xOWm9D/3+IugCPCipFZkQnR0RT0h6CZgt6XLgL8AogIhYImk2sBTYAXzXvxIpiLr2y68lDSIzvH4HuAq8X5rYFPxZaW6mFvpz0qJ/jmtmZum16ENVZmaWnoPDzMxScXCYmVkqDg4zM0vFwWFmZqk4OMxSkLQl+benpH9t5LYn50z/v8Zs36yxODjM9k5PIFVwJNel1Ge34IiIoSn7ZLZfODjM9s4U4JTkeQcTk5sy/lzSguTmclcBSDpd0nOSHgYWJ/N+L2lh8qyRK5N5U4ADkvZmJvOqRzdK2n5D0mJJF2a1/bykOZKWS5qZ3JLerKBa+pXjZntrEvCDiBgGkATAxxFxgqQvAy9K+lNSdgjQP7mVNcC3IuKj5HYqCyQ9FhGTJI1PbuyYaySZG9YVAx2TOvOSZYOBfmTuOfQimfsX/bmxN9Ysm0ccZo3jbOCbya3gXwE6kLkXEMD8rNAA+J6kRcDLZG46dzT1+0fgkeTGdeuAF4ATstquTG5oV0HmEJpZQXnEYdY4BEyIiKd2mymdDvwtZ/qfgK9FxCeSngfa5dF2XbZmvd+JP9O2H3jEYbZ3/gocnDX9FPDt5FG3SDpG0oG11DsU2JiERm/gpKxl26vr55gHXJicR+kEnIrvNGtNyP87Mds7rwM7kkNODwC3kzlM9GpygrqKzx6jmu1JYJyk14EVZA5XVZsOvC7p1Yi4OGt+GfA1YBGZO55eGxEfJMFjtt/57rhmZpaKD1WZmVkqDg4zM0vFwWFmZqk4OMzMLBUHh5mZpeLgMDOzVBwcZmaWyv8HVkVVWsilgm0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#learning_curve for LR\n",
    "learn_curve(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22295d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c6de01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.89      0.88       500\n",
      "           1       0.89      0.87      0.88       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "CPU times: total: 797 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##Data without dimensionality reduction and feature extraction\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('../datasets/celeba_test/img/',1000)\n",
    "img_data_test = transfer.fit_transform(img_data_test)\n",
    "#get label_test\n",
    "label_test=get_label('../datasets/celeba_test/labels.csv','gender')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"LogisticRegression_gender.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e8c2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.47      0.49       500\n",
      "           1       0.50      0.52      0.51       500\n",
      "\n",
      "    accuracy                           0.50      1000\n",
      "   macro avg       0.50      0.50      0.50      1000\n",
      "weighted avg       0.50      0.50      0.50      1000\n",
      "\n",
      "CPU times: total: 5.98 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Data with dimensionality reduction by PCA\n",
    "#get and preprocess image data for testing\n",
    "img_data_test=load_image_to_vector('../datasets/celeba_test/img/',1000)\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('../datasets/celeba_test/labels.csv','gender')\n",
    "#pca for image data\n",
    "img_data_test=img_data_pca(img_data_test,100)\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"LogisticRegression_gender_PCA.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e3b663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.96      0.97       500\n",
      "           1       0.96      0.97      0.97       500\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "CPU times: total: 3min 37s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Data with feature extraction\n",
    "#get and preprocess image data for testing\n",
    "#img_data_test=face_feature_read('face_feature_test')\n",
    "img_data_test=face_feature('celeba_test',1000)\n",
    "img_data_test = transfer.fit_transform(img_data_test )\n",
    "#get label\n",
    "label_test=get_label('../datasets/celeba_test/labels.csv','gender')\n",
    "#load model\n",
    "loaded_model = pickle.load(open(\"LogisticRegression_gender_dlib.dat\",\"rb\"))\n",
    "label_pred=loaded_model.predict(img_data_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(label_test,label_pred)))\n",
    "print(classification_report(label_test,label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c3790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
